{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "mnist is of type base.Datasets. Datasets are namedtuples (See https://docs.python.org/3.6/library/collections.html#collections.namedtuple).\n",
    "\n",
    "Datasets are defined in /home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py. Datasets contain three objects of type mnist.DataSet.\n",
    "\n",
    "The class DataSet is defined in /home/rm/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py.\n",
    "\n",
    "The class Dataset has the following properties & methods that are used in the code below.\n",
    "\n",
    "    the property: num_examples the method: next_batch()\n",
    "\n",
    "For code that illustrates the above, see the set of print() statements in MNIST-mod1.ipynb\n",
    "## Change to the code\n",
    "\n",
    "mnist.Datasets are no longer to be used. The training, validation, and test data will now be read in differently. So the functionality provided by mnist.Datasets have to be replicated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type='text/css'>\n",
       ".hll { background-color: #ffffcc }\n",
       ".c { color: #408080; font-style: italic } /* Comment */\n",
       ".err { border: 1px solid #FF0000 } /* Error */\n",
       ".k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".o { color: #666666 } /* Operator */\n",
       ".ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".gd { color: #A00000 } /* Generic.Deleted */\n",
       ".ge { font-style: italic } /* Generic.Emph */\n",
       ".gr { color: #FF0000 } /* Generic.Error */\n",
       ".gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".gi { color: #00A000 } /* Generic.Inserted */\n",
       ".go { color: #888888 } /* Generic.Output */\n",
       ".gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".gs { font-weight: bold } /* Generic.Strong */\n",
       ".gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".gt { color: #0044DD } /* Generic.Traceback */\n",
       ".kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".kt { color: #B00040 } /* Keyword.Type */\n",
       ".m { color: #666666 } /* Literal.Number */\n",
       ".s { color: #BA2121 } /* Literal.String */\n",
       ".na { color: #7D9029 } /* Name.Attribute */\n",
       ".nb { color: #008000 } /* Name.Builtin */\n",
       ".nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".no { color: #880000 } /* Name.Constant */\n",
       ".nd { color: #AA22FF } /* Name.Decorator */\n",
       ".ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".nf { color: #0000FF } /* Name.Function */\n",
       ".nl { color: #A0A000 } /* Name.Label */\n",
       ".nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".nv { color: #19177C } /* Name.Variable */\n",
       ".ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".mf { color: #666666 } /* Literal.Number.Float */\n",
       ".mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".sx { color: #008000 } /* Literal.String.Other */\n",
       ".sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".vc { color: #19177C } /* Name.Variable.Class */\n",
       ".vg { color: #19177C } /* Name.Variable.Global */\n",
       ".vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from modGetMNIST_Data_Labels.ipynb\n"
     ]
    }
   ],
   "source": [
    "#Import the jupyter notebook that interfaces to the module that reads the MINST data\n",
    "#The read functionality is provided by Jupyter notebook: \n",
    "    #/home/rm/cjalmeida/tf_mnist/data.ipynb\n",
    "#The MINST data files are in:  /home/rm/cjalmeida/input\n",
    "\n",
    "#See https://gist.github.com/DCAL12/1a872bd63bedfb7b12612c8a7ec0f52e#file-notebook_importing-py\n",
    "from nbextensions import notebook_importing\n",
    "from modGetMNIST_Data_Labels import fnGetCompleteListOfTraining_Data_Labels\n",
    "from modGetMNIST_Data_Labels import fnGetCompleteListOfTest_Data_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 40\n",
    "display_step = 1\n",
    "######################\n",
    "#RM\n",
    "H_IN_PIXELS = 28\n",
    "W_IN_PIXELS = 28\n",
    "INPUT_SHAPE = [None, H_IN_PIXELS * W_IN_PIXELS] #Shape of Input data\n",
    "OUTPUT_SHAPE = [None, 10] #Shape of Labels\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT for the graph\n",
    "#######################\n",
    "# See \"Wrapping all together -> Switch between train and test set using Initializable iterator\"\n",
    "# in Tensorflow-Dataset-Tutorial/dataset_tutorial.ipynb\n",
    "#\n",
    "# create a placeholder to dynamically switch between batch sizes\n",
    "\n",
    "# tf Graph input\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "\n",
    "x, y = tf.placeholder(tf.float64, shape=INPUT_SHAPE), \\\n",
    "                tf.placeholder(tf.int8, shape=OUTPUT_SHAPE)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size).repeat()\n",
    "\n",
    "iter = dataset.make_initializable_iterator()\n",
    "BatchOfFeatures_Labels = iter.get_next()\n",
    "\n",
    "####################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 256 # 2nd layer num features\n",
    "n_input = INPUT_SHAPE[1] #784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = OUTPUT_SHAPE[1] #10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "Features = tf.placeholder(tf.float64, shape=INPUT_SHAPE)\n",
    "TrueLabels = tf.placeholder(tf.float64, shape=OUTPUT_SHAPE)\n",
    "\n",
    "#weights layer 1\n",
    "h = tf.Variable(tf.random_normal([n_input, n_hidden_1], dtype=tf.float64))\n",
    "#bias layer 1\n",
    "bias_layer_1 = tf.Variable(tf.random_normal([n_hidden_1], dtype=tf.float64))\n",
    "#layer 1\n",
    "layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(Features,h),bias_layer_1))\n",
    "\n",
    "#weights layer 2\n",
    "w = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], dtype=tf.float64))\n",
    "#bias layer 2\n",
    "bias_layer_2 = tf.Variable(tf.random_normal([n_hidden_2], dtype=tf.float64))\n",
    "#layer 2\n",
    "layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1,w),bias_layer_2))\n",
    "\n",
    "#weights output layer\n",
    "output_weights = tf.Variable(tf.random_normal([n_hidden_2, n_classes], dtype=tf.float64))\n",
    "#biar output layer\n",
    "bias_output = tf.Variable(tf.random_normal([n_classes], dtype=tf.float64))\n",
    "#output layer\n",
    "output_layer = tf.matmul(layer_2, output_weights) + bias_output\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=TrueLabels))\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) \n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "  \n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(output_layer, 1), tf.argmax(TrueLabels, 1))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "# Initializing the variables\n",
    "init_vars = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/rm/cjalmeida/tf_mnist/data.ipynb\n",
      "Path to Input Files:  /home/rm/cjalmeida/input\n",
      "\n",
      "DONE: fnGetCompleteListOfMNIST_Data_Labels\n"
     ]
    }
   ],
   "source": [
    "#Plot settings\n",
    "avg_set = []\n",
    "epoch_set=[]\n",
    "\n",
    "#Read the complete MNIST training data file\n",
    "training_images, training_labels, no_of_training_images = fnGetCompleteListOfTraining_Data_Labels()\n",
    "\n",
    "#print(\"training_images.shape, before flattening: \", training_images.shape)\n",
    "assert(60000 == no_of_training_images)\n",
    "assert(training_images.shape == (no_of_training_images, H_IN_PIXELS, W_IN_PIXELS, 1))\n",
    "training_images = training_images.reshape(no_of_training_images, 28 * 28)\n",
    "#print(\"training_images.shape after flattening: \", training_images.shape)\n",
    "assert(training_images.shape == (no_of_training_images, H_IN_PIXELS * W_IN_PIXELS))\n",
    "assert(training_labels.shape == (no_of_training_images, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 cost= 1.487540856\n",
      "Epoch: 0001 cost= 0.504240049\n",
      "Epoch: 0002 cost= 0.365268747\n",
      "Epoch: 0003 cost= 0.290673331\n",
      "Epoch: 0004 cost= 0.241743100\n",
      "Epoch: 0005 cost= 0.206630235\n",
      "Epoch: 0006 cost= 0.178778386\n",
      "Epoch: 0007 cost= 0.155253842\n",
      "Epoch: 0008 cost= 0.139133960\n",
      "Epoch: 0009 cost= 0.120337043\n",
      "Epoch: 0010 cost= 0.108453417\n",
      "Epoch: 0011 cost= 0.096824847\n",
      "Epoch: 0012 cost= 0.086791132\n",
      "Epoch: 0013 cost= 0.078578837\n",
      "Epoch: 0014 cost= 0.070969728\n",
      "Epoch: 0015 cost= 0.062775660\n",
      "Epoch: 0016 cost= 0.057494334\n",
      "Epoch: 0017 cost= 0.051823443\n",
      "Epoch: 0018 cost= 0.046989994\n",
      "Epoch: 0019 cost= 0.042253545\n",
      "Epoch: 0020 cost= 0.038496508\n",
      "Epoch: 0021 cost= 0.036906943\n",
      "Epoch: 0022 cost= 0.031751649\n",
      "Epoch: 0023 cost= 0.029945544\n",
      "Epoch: 0024 cost= 0.029411788\n",
      "Epoch: 0025 cost= 0.025928579\n",
      "Epoch: 0026 cost= 0.022971163\n",
      "Epoch: 0027 cost= 0.023553071\n",
      "Epoch: 0028 cost= 0.021766855\n",
      "Epoch: 0029 cost= 0.019369720\n",
      "Epoch: 0030 cost= 0.017060637\n",
      "Epoch: 0031 cost= 0.017552335\n",
      "Epoch: 0032 cost= 0.017637358\n",
      "Epoch: 0033 cost= 0.015697914\n",
      "Epoch: 0034 cost= 0.015430434\n",
      "Epoch: 0035 cost= 0.017529750\n",
      "Epoch: 0036 cost= 0.013796867\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_vars)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_no_of_batches = no_of_training_images//BATCH_SIZE\n",
    "######################################\n",
    "        # initialise iterator with train data\n",
    "        sess.run(iter.initializer, feed_dict={ x: training_images,\\\n",
    "                                              y: training_labels, \\\n",
    "                                              batch_size: BATCH_SIZE})\n",
    "######################################\n",
    "        # Loop over all batches\n",
    "        for batch_no in range(total_no_of_batches):\n",
    "            #if(0 == batch_no):\n",
    "            #    print(\"Epoch No: {}, Batch No:{}\".format(epoch, batch_no))\n",
    "            ListOfFeatures_Labels = sess.run(BatchOfFeatures_Labels)\n",
    "            batch_Features = ListOfFeatures_Labels[0].astype(np.float64)\n",
    "            batch_Labels = ListOfFeatures_Labels[1]\n",
    "\n",
    "            assert(batch_Features.shape == (BATCH_SIZE, H_IN_PIXELS * W_IN_PIXELS))\n",
    "\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, \\\n",
    "                     feed_dict={Features: batch_Features, \\\n",
    "                               TrueLabels: batch_Labels})\n",
    "            # Compute average loss\n",
    "            avg_cost += (sess.run(cost, \\\n",
    "                                 feed_dict={Features: batch_Features, \\\n",
    "                                           TrueLabels: batch_Labels}) \\\n",
    "                                )/total_no_of_batches\n",
    "        # Display logs per epoch step\n",
    "        if epoch % (1) == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "        avg_set.append(avg_cost)\n",
    "        epoch_set.append(epoch+1)\n",
    "        \n",
    "    #Plot it\n",
    "    plt.plot(epoch_set,avg_set, 'o', label='Logistic Regression Training phase')\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print (\"\\nDONE: Training phase\")\n",
    "    ## Test model\n",
    "    #Check accuracy using test data\n",
    "    test_images, test_labels, no_of_test_images = fnGetCompleteListOfTest_Data_Labels()\n",
    "\n",
    "    assert(10000 == no_of_test_images)\n",
    "    assert(test_images.shape == (no_of_test_images, H_IN_PIXELS, W_IN_PIXELS, 1))\n",
    "\n",
    "    test_images = (test_images.reshape(no_of_test_images, 28 * 28)).astype(np.float64)\n",
    "\n",
    "    assert(test_images.shape == (no_of_test_images, H_IN_PIXELS * W_IN_PIXELS))\n",
    "    assert(test_labels.shape == (no_of_test_images, 10))\n",
    "\n",
    "    print (\"Model accuracy (with Test Data):\", accuracy.eval({Features: test_images, \\\n",
    "                                          TrueLabels: test_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
